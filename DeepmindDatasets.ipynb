{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AeroEng16/GNN_learning/blob/main/DeepmindDatasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "**Trying Deepmind Research Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google-deepmind/deepmind-research\n",
        "!git clone https://github.com/Mohamedelrefaie/DrivAerNet"
      ],
      "metadata": {
        "id": "UxmA-_TuepKo",
        "outputId": "3072f6ba-66c0-4710-d428-fe1456de65e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepmind-research'...\n",
            "remote: Enumerating objects: 3046, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 3046 (delta 140), reused 33 (delta 33), pack-reused 2845 (from 4)\u001b[K\n",
            "Receiving objects: 100% (3046/3046), 92.07 MiB | 32.64 MiB/s, done.\n",
            "Resolving deltas: 100% (1568/1568), done.\n",
            "Cloning into 'DrivAerNet'...\n",
            "remote: Enumerating objects: 686, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 686 (delta 63), reused 47 (delta 47), pack-reused 609 (from 2)\u001b[K\n",
            "Receiving objects: 100% (686/686), 1023.38 KiB | 18.27 MiB/s, done.\n",
            "Resolving deltas: 100% (346/346), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install /content/DrivAerNet/requirements.txt\n",
        "!pip install pyvista\n",
        "!pip install trimesh\n",
        "!pip install torch-geometric\n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import trimesh\n",
        "from torch.utils.data import Dataset\n",
        "import pyvista as pv\n",
        "import seaborn as sns\n",
        "from typing import Callable, Optional, Tuple"
      ],
      "metadata": {
        "id": "ywtHUXy0-jFe",
        "outputId": "8ecf7d0d-70a3-4f92-9bf1-d7a81ac97f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvista in /usr/local/lib/python3.11/dist-packages (0.45.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from pyvista) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pyvista) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pyvista) (11.3.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from pyvista) (1.8.2)\n",
            "Requirement already satisfied: scooby>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from pyvista) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyvista) (4.14.1)\n",
            "Requirement already satisfied: vtk!=9.4.0 in /usr/local/lib/python3.11/dist-packages (from pyvista) (9.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.1->pyvista) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->pyvista) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->pyvista) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.1->pyvista) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->pyvista) (2025.7.14)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (4.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from trimesh) (2.0.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataAugmentation:\n",
        "    \"\"\"\n",
        "    Class encapsulating various data augmentation techniques for point clouds.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def translate_pointcloud(pointcloud: torch.Tensor, translation_range: Tuple[float, float] = (2./3., 3./2.)) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Translates the pointcloud by a random factor within a given range.\n",
        "\n",
        "        Args:\n",
        "            pointcloud: The input point cloud as a torch.Tensor.\n",
        "            translation_range: A tuple specifying the range for translation factors.\n",
        "\n",
        "        Returns:\n",
        "            Translated point cloud as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Randomly choose translation factors and apply them to the pointcloud\n",
        "        xyz1 = np.random.uniform(low=translation_range[0], high=translation_range[1], size=[3])\n",
        "        xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n",
        "        translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n",
        "        return torch.tensor(translated_pointcloud, dtype=torch.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def jitter_pointcloud(pointcloud: torch.Tensor, sigma: float = 0.01, clip: float = 0.02) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Adds Gaussian noise to the pointcloud.\n",
        "\n",
        "        Args:\n",
        "            pointcloud: The input point cloud as a torch.Tensor.\n",
        "            sigma: Standard deviation of the Gaussian noise.\n",
        "            clip: Maximum absolute value for noise.\n",
        "\n",
        "        Returns:\n",
        "            Jittered point cloud as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Add Gaussian noise and clip to the specified range\n",
        "        N, C = pointcloud.shape\n",
        "        jittered_pointcloud = pointcloud + torch.clamp(sigma * torch.randn(N, C), -clip, clip)\n",
        "        return jittered_pointcloud\n",
        "\n",
        "    @staticmethod\n",
        "    def drop_points(pointcloud: torch.Tensor, drop_rate: float = 0.1) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Randomly removes points from the point cloud based on the drop rate.\n",
        "\n",
        "        Args:\n",
        "            pointcloud: The input point cloud as a torch.Tensor.\n",
        "            drop_rate: The percentage of points to be randomly dropped.\n",
        "\n",
        "        Returns:\n",
        "            The point cloud with points dropped as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Calculate the number of points to drop\n",
        "        num_drop = int(drop_rate * pointcloud.size(0))\n",
        "        # Generate random indices for points to drop\n",
        "        drop_indices = np.random.choice(pointcloud.size(0), num_drop, replace=False)\n",
        "        # Drop the points\n",
        "        keep_indices = np.setdiff1d(np.arange(pointcloud.size(0)), drop_indices)\n",
        "        dropped_pointcloud = pointcloud[keep_indices, :]\n",
        "        return dropped_pointcloud\n",
        "\n",
        "class DrivAerNetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset class for the DrivAerNet dataset, handling loading, transforming, and augmenting 3D car models.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir: str, csv_file: str, num_points: int, transform: Optional[Callable] = None):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the DrivAerNetDataset instance.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Directory containing the STL files for 3D car models.\n",
        "            csv_file: Path to the CSV file with metadata for the models.\n",
        "            num_points: Fixed number of points to sample from each 3D model.\n",
        "            transform: Optional transform function to apply to each sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        # Attempt to load the metadata CSV file and log errors if unsuccessful\n",
        "        try:\n",
        "            self.data_frame = pd.read_csv(csv_file)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load CSV file: {csv_file}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        self.transform = transform  # Transformation function to be applied to each sample\n",
        "        self.num_points = num_points  # Number of points each sample should have\n",
        "        self.augmentation = DataAugmentation()  # Instantiate the DataAugmentation class\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def min_max_normalize(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Normalizes the data to the range [0, 1] based on min and max values.\n",
        "\n",
        "        Args:\n",
        "            data: Input data as a torch.Tensor.\n",
        "\n",
        "        Returns:\n",
        "            Normalized data as a torch.Tensor.\n",
        "        \"\"\"\n",
        "        # Compute min and max values for normalization\n",
        "        # Assuming data is a PyTorch Tensor of shape [num_points, num_features]\n",
        "        min_vals, _ = data.min(dim=0, keepdim=True)  # Keep dimension for broadcasting\n",
        "        max_vals, _ = data.max(dim=0, keepdim=True)  # Keep dimension for broadcasting\n",
        "\n",
        "        # Ensure min_vals and max_vals are Tensors compatible for broadcasting\n",
        "        normalized_data = (data - min_vals) / (max_vals - min_vals)\n",
        "        return normalized_data\n",
        "\n",
        "    def _sample_or_pad_vertices(self, vertices: torch.Tensor, num_points: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Subsamples or pads the vertices of the model to a fixed number of points.\n",
        "\n",
        "        Args:\n",
        "            vertices: The vertices of the 3D model as a torch.Tensor.\n",
        "            num_points: The desired number of points for the model.\n",
        "\n",
        "        Returns:\n",
        "            The vertices standardized to the specified number of points.\n",
        "        \"\"\"\n",
        "        num_vertices = vertices.size(0)\n",
        "        # Subsample the vertices if there are more than the desired number\n",
        "        if num_vertices > num_points:\n",
        "            indices = np.random.choice(num_vertices, num_points, replace=False)\n",
        "            vertices = vertices[indices]\n",
        "        # Pad with zeros if there are fewer vertices than desired\n",
        "        elif num_vertices < num_points:\n",
        "            padding = torch.zeros((num_points - num_vertices, 3), dtype=torch.float32)\n",
        "            vertices = torch.cat((vertices, padding), dim=0)\n",
        "        return vertices\n",
        "    def __getitem__(self, idx: int, apply_augmentations: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Retrieves a sample and its corresponding label from the dataset, with an option to apply augmentations.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to retrieve.\n",
        "            apply_augmentations (bool, optional): Whether to apply data augmentations. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: The sample (point cloud) and its label (Cd value).\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Extract the relevant row from the DataFrame using the provided index\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        design_id = row['Design']\n",
        "        cd_value = row['Average Cd']\n",
        "        geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "\n",
        "        # Load the STL file and handle errors\n",
        "        try:\n",
        "            mesh = trimesh.load(geometry_path, force='mesh')\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        # Convert mesh vertices to a tensor and standardize to the specified number of points\n",
        "        vertices = torch.tensor(mesh.vertices, dtype=torch.float32)\n",
        "        vertices = self._sample_or_pad_vertices(vertices, self.num_points)\n",
        "\n",
        "        # Apply data augmentations if enabled\n",
        "        if apply_augmentations:\n",
        "            vertices = self.augmentation.translate_pointcloud(vertices.numpy())\n",
        "            vertices = self.augmentation.jitter_pointcloud(vertices)\n",
        "\n",
        "        # Apply optional transformations\n",
        "        if self.transform:\n",
        "            vertices = self.transform(vertices)\n",
        "\n",
        "        # Normalize the features of the point cloud\n",
        "        point_cloud_normalized = self.min_max_normalize(vertices)\n",
        "\n",
        "        cd_value = torch.tensor(float(cd_value), dtype=torch.float32).view(-1)\n",
        "        #return point_cloud_normalized, cd_value\n",
        "        return vertices, cd_value\n",
        "\n",
        "    # Visualization methods for the DrivAerNetDataset class\n",
        "\n",
        "    def visualize_mesh(self, idx):\n",
        "        \"\"\"\n",
        "        Visualize the STL mesh for a specific design from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the design to visualize in the dataset.\n",
        "\n",
        "        This function loads the mesh from the STL file corresponding to the design ID at the given index,\n",
        "        wraps it using PyVista for visualization, and then sets up a PyVista plotter to display the mesh.\n",
        "        \"\"\"\n",
        "        # Retrieve design ID and construct the file path for the STL file\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        design_id = row['Design']\n",
        "        geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "\n",
        "        # Attempt to load the mesh from the STL file and handle potential errors\n",
        "        try:\n",
        "            mesh = trimesh.load(geometry_path, force='mesh')\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        # Convert the trimesh mesh to a PyVista mesh for visualization\n",
        "        pv_mesh = pv.wrap(mesh)\n",
        "\n",
        "        # Set up the PyVista plotter\n",
        "        plotter = pv.Plotter()\n",
        "        plotter.add_mesh(pv_mesh, color='lightgrey', show_edges=True)\n",
        "        plotter.add_axes()\n",
        "\n",
        "        # Define a specific camera position for a consistent viewing angle\n",
        "        camera_position = [(-11.073024242161921, -5.621499358347753, 5.862225824910342),\n",
        "                           (1.458462064391673, 0.002314306982062475, 0.6792134746589196),\n",
        "                           (0.34000174095454166, 0.10379556639001211, 0.9346792479485448)]\n",
        "        plotter.camera_position = camera_position\n",
        "\n",
        "        # Display the plotter window with the mesh\n",
        "        plotter.show()\n",
        "\n",
        "    def visualize_mesh_withNode(self, idx):\n",
        "        \"\"\"\n",
        "        Visualizes the mesh for a specific design from the dataset with nodes highlighted.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the design to visualize in the dataset.\n",
        "\n",
        "        This function loads the mesh from the STL file and highlights the nodes (vertices) of the mesh using spheres.\n",
        "        It uses seaborn to obtain visually distinct colors for the mesh and nodes.\n",
        "        \"\"\"\n",
        "        # Retrieve design ID and construct the file path for the STL file\n",
        "        row = self.data_frame.iloc[idx]\n",
        "        design_id = row['Design']\n",
        "        geometry_path = os.path.join(self.root_dir, f\"{design_id}.stl\")\n",
        "\n",
        "        # Attempt to load the mesh from the STL file and handle potential errors\n",
        "        try:\n",
        "            mesh = trimesh.load(geometry_path, force='mesh')\n",
        "            pv_mesh = pv.wrap(mesh)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load STL file: {geometry_path}. Error: {e}\")\n",
        "            raise\n",
        "\n",
        "        # Set up the PyVista plotter\n",
        "        plotter = pv.Plotter()\n",
        "        sns_blue = sns.color_palette(\"colorblind\")[0]  # Using seaborn to get a visually distinct blue color\n",
        "\n",
        "        # Add the mesh to the plotter with light grey color and black edges\n",
        "        plotter.add_mesh(pv_mesh, color='lightgrey', show_edges=True, edge_color='black')\n",
        "\n",
        "        # Highlight nodes (vertices) of the mesh as blue spheres\n",
        "        nodes = pv_mesh.points\n",
        "        plotter.add_points(nodes, color=sns_blue, point_size=10, render_points_as_spheres=True)\n",
        "\n",
        "        # Add axes for orientation and display the plotter window\n",
        "        plotter.add_axes()\n",
        "        plotter.show()\n",
        "\n",
        "    def visualize_point_cloud(self, idx):\n",
        "        \"\"\"\n",
        "        Visualizes the point cloud for a specific design from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the design to visualize in the dataset.\n",
        "\n",
        "        This function retrieves the vertices for the specified design, converts them into a point cloud,\n",
        "        and uses the z-coordinate for color mapping. PyVista's Eye-Dome Lighting is enabled for improved depth perception.\n",
        "        \"\"\"\n",
        "        # Retrieve vertices and corresponding CD value for the specified index\n",
        "        vertices, _ = self.__getitem__(idx)\n",
        "        vertices = vertices.numpy()\n",
        "\n",
        "        # Convert vertices to a PyVista PolyData object for visualization\n",
        "        point_cloud = pv.PolyData(vertices)\n",
        "        colors = vertices[:, 2]  # Using the z-coordinate for color mapping\n",
        "        point_cloud[\"colors\"] = colors  # Add the colors to the point cloud\n",
        "\n",
        "        # Set up the PyVista plotter\n",
        "        plotter = pv.Plotter()\n",
        "\n",
        "        # Add the point cloud to the plotter with color mapping based on the z-coordinate\n",
        "        plotter.add_points(point_cloud, scalars=\"colors\", cmap=\"Blues\", point_size=3, render_points_as_spheres=True)\n",
        "\n",
        "        # Enable Eye-Dome Lighting for better depth perception\n",
        "        plotter.enable_eye_dome_lighting()\n",
        "\n",
        "        # Add axes for orientation and display the plotter window\n",
        "        plotter.add_axes()\n",
        "        camera_position = [(-11.073024242161921, -5.621499358347753, 5.862225824910342),\n",
        "                           (1.458462064391673, 0.002314306982062475, 0.6792134746589196),\n",
        "                           (0.34000174095454166, 0.10379556639001211, 0.9346792479485448)]\n",
        "\n",
        "        # Set the camera position\n",
        "        plotter.camera_position = camera_position\n",
        "\n",
        "        plotter.show()\n",
        "    def visualize_augmentations(self, idx):\n",
        "        \"\"\"\n",
        "        Visualizes various augmentations applied to the point cloud of a specific design in the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample in the dataset to be visualized.\n",
        "\n",
        "        This function retrieves the original point cloud for the specified design and then applies a series of augmentations,\n",
        "        including translation, jittering, and point dropping. Each version of the point cloud (original and augmented) is then\n",
        "        visualized in a 2x2 grid using PyVista to illustrate the effects of these augmentations.\n",
        "        \"\"\"\n",
        "        # Retrieve the original point cloud without applying any augmentations\n",
        "        vertices, _ = self.__getitem__(idx, apply_augmentations=False)\n",
        "        original_pc = pv.PolyData(vertices.numpy())\n",
        "\n",
        "        # Apply translation augmentation to the original point cloud\n",
        "        translated_pc = self.augmentation.translate_pointcloud(vertices.numpy())\n",
        "        # Apply jitter augmentation to the translated point cloud\n",
        "        jittered_pc = self.augmentation.jitter_pointcloud(translated_pc)\n",
        "        # Apply point dropping augmentation to the jittered point cloud\n",
        "        dropped_pc = self.augmentation.drop_points(jittered_pc)\n",
        "\n",
        "        # Initialize a PyVista plotter with a 2x2 grid for displaying the point clouds\n",
        "        plotter = pv.Plotter(shape=(2, 2))\n",
        "\n",
        "        # Display the original point cloud in the top left corner of the grid\n",
        "        plotter.subplot(0, 0)  # Select the first subplot\n",
        "        plotter.add_text(\"Original Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(original_pc, color='black', point_size=3)  # Add the original point cloud to the plot\n",
        "\n",
        "        # Display the translated point cloud in the top right corner of the grid\n",
        "        plotter.subplot(0, 1)  # Select the second subplot\n",
        "        plotter.add_text(\"Translated Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(pv.PolyData(translated_pc.numpy()), color='lightblue', point_size=3)  # Add the translated point cloud to the plot\n",
        "\n",
        "        # Display the jittered point cloud in the bottom left corner of the grid\n",
        "        plotter.subplot(1, 0)  # Select the third subplot\n",
        "        plotter.add_text(\"Jittered Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(pv.PolyData(jittered_pc.numpy()), color='lightgreen', point_size=3)  # Add the jittered point cloud to the plot\n",
        "\n",
        "        # Display the dropped point cloud in the bottom right corner of the grid\n",
        "        plotter.subplot(1, 1)  # Select the fourth subplot\n",
        "        plotter.add_text(\"Dropped Point Cloud\", font_size=10)  # Add descriptive text\n",
        "        plotter.add_mesh(pv.PolyData(dropped_pc.numpy()), color='salmon', point_size=3)  # Add the dropped point cloud to the plot\n",
        "\n",
        "        # Display the plot with all point clouds\n",
        "        plotter.show()\n"
      ],
      "metadata": {
        "id": "BfPz5mwa7SK4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python DrivAerNet/tutorials/DrivAerNet_tutorial.py"
      ],
      "metadata": {
        "id": "Mr1PQLAS9qLS",
        "outputId": "3feacbe6-ff5e-4e50-a158-f2d9c3acc095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure(2000x1000)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DrivAerNet/tutorials/DrivAerNet_tutorial.py\", line 86, in <module>\n",
            "    stl_files = [f for f in os.listdir(folder_path) if f.endswith('.stl')]\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../DrivAerNet_STLs_Combined'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python DrivAerNet/DeepSurrogates/DrivAerNetDataset.py\n",
        "dataset = DrivAerNetDataset(root_dir='../DrivAerNet_STLs_Combined',\n",
        "                                     csv_file='/content/DrivAerNet/ParametricModels/DrivAerNet_ParametricData.csv',\n",
        "                                     num_points=500000)"
      ],
      "metadata": {
        "id": "XV0dCxqK5k-7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.visualize_mesh_withNode(300)  # Visualize the mesh of the first sample\n"
      ],
      "metadata": {
        "id": "omeow_tk7d4P",
        "outputId": "a3ec98fe-2e6e-4c50-ca1d-cb2248f27866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Design'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Design'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-27-2693086803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-21-3545592326.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx, apply_augmentations)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# Extract the relevant row from the DataFrame using the provided index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mdesign_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Design'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mcd_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Average Cd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mgeometry_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{design_id}.stl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Design'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r deepmind-research/meshgraphnets/requirements.txt"
      ],
      "metadata": {
        "id": "SZfjO46jgxhB",
        "outputId": "8e4f8072-4920-4cbb-df25-eb21a059fdf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu<2,>=1.15 (from versions: 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-gpu<2,>=1.15\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ${DATA}\n",
        "!bash deepmind-research/meshgraphnets/download_dataset.sh cylinder_flow ${DATA}"
      ],
      "metadata": {
        "id": "1-zInXFRgUe_",
        "outputId": "ca577a8b-c691-4fcf-f94f-2008ca3b3428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: missing operand\n",
            "Try 'mkdir --help' for more information.\n",
            "--2025-07-25 12:16:49--  https://storage.googleapis.com/dm-meshgraphnets/cylinder_flow/meta.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.207, 172.217.204.207, 172.217.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 883 [application/octet-stream]\n",
            "Saving to: ‘/cylinder_flow/meta.json’\n",
            "\n",
            "/cylinder_flow/meta 100%[===================>]     883  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-25 12:16:50 (16.1 MB/s) - ‘/cylinder_flow/meta.json’ saved [883/883]\n",
            "\n",
            "--2025-07-25 12:16:50--  https://storage.googleapis.com/dm-meshgraphnets/cylinder_flow/train.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.207, 172.217.204.207, 172.217.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13645805387 (13G) [application/octet-stream]\n",
            "Saving to: ‘/cylinder_flow/train.tfrecord’\n",
            "\n",
            "/cylinder_flow/trai 100%[===================>]  12.71G   146MB/s    in 2m 44s  \n",
            "\n",
            "2025-07-25 12:19:34 (79.3 MB/s) - ‘/cylinder_flow/train.tfrecord’ saved [13645805387/13645805387]\n",
            "\n",
            "--2025-07-25 12:19:34--  https://storage.googleapis.com/dm-meshgraphnets/cylinder_flow/valid.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.207, 172.217.204.207, 172.217.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1363987289 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘/cylinder_flow/valid.tfrecord’\n",
            "\n",
            "/cylinder_flow/vali 100%[===================>]   1.27G  96.2MB/s    in 19s     \n",
            "\n",
            "2025-07-25 12:19:54 (66.8 MB/s) - ‘/cylinder_flow/valid.tfrecord’ saved [1363987289/1363987289]\n",
            "\n",
            "--2025-07-25 12:19:54--  https://storage.googleapis.com/dm-meshgraphnets/cylinder_flow/test.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.207, 172.217.204.207, 172.217.203.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1355376404 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘/cylinder_flow/test.tfrecord’\n",
            "\n",
            "/cylinder_flow/test 100%[===================>]   1.26G  29.8MB/s    in 15s     \n",
            "\n",
            "2025-07-25 12:20:09 (84.7 MB/s) - ‘/cylinder_flow/test.tfrecord’ saved [1355376404/1355376404]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python deepmind.research"
      ],
      "metadata": {
        "id": "W5fVFcP4iYc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}